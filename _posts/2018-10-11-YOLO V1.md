code: [https://github.com/gliese581gg/YOLO_tensorflow](https://github.com/gliese581gg/YOLO_tensorflow)

[https://zhuanlan.zhihu.com/p/32525231](https://zhuanlan.zhihu.com/p/32525231)     目标检测-YOLO原理与实现

# 创新点
>- **端到端训练及推断 + 改革区域候选框目标检测框架 + 实时目标检测**

>改革了区域候选框式检测框架：RCNN系列均需要生成候选框，在候选框上进行分类和回归，但是候选框之间有重叠，会带来很多重复的工作。YOLO将全图划分成`S*S`的格子，每个格子负责中心在该格子的目标检测，采用一次性预测所有格子所含的目标bbox、定位置信度、所有类别概率向量来将这一问题一次性解决(one-shot)

# 设计理念
YOLO的CNN网络将输入的图片分割成`S*S`网格，然后每个网格负责去检测那些中心点落在该格子内的目标，如图所示，可以看到狗这个目标的中心落在左下角一个单元格内，那么该单元格负责预测这个狗。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/yolo-dog.png)

每个单元格会预测B个边界框以及边界框的置信度。该置信度包含两个部分`P(object) * IoU`，一个是边界框含有目标的可能性大小`P(object)`。二是边界框的准确度[交并比`IoU`]。每个边界框的预测值包含5个元素`(x,y,w,h,c)`，代表着坐标、宽高、置信度。并且每个单元格还要预测出c个类别概率值`P_i(class_i/object)`。因此各个边界框类别置信度为`P(class_i/object)*P(object)*IoU = P(class_i)*IoU`. 一般会根据类别置信度来过滤网络的预选框。

简单小结：每个单元格需要预测`(B*5+C)`个值。如果将输入图片划分为`S*S`网络，那么最终的预测值为`S*S*(B*5+C)`大小的张量。如：对于PASCAL VOC数据，其共有20个类别，如果使用`S=7,B=2`，那么最终的预测结果就是`7×7×30`大小的张量。

# 网络结构
YOLO采用CNN来提取特征，然后全连接层来得到预测值。网络结构参考的是GooLeNet模型，包含24个卷积层和2个全连接层。对于卷积层和全连接层采用Leaky RELU作为激活函数`max(x,0.1x)`，最后一层采用线性激活函数。除了上面这个结构，还有个轻量级版本Fast Yolo，其仅使用9个卷积层，并且卷积层中使用更少的卷积核。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/yolo-net.png)

网络最后输出的是`7*7*30`的张量，对于每个单元格的张量而言，前20个元素是类别概率值，然后2个是边界框置信度，两者相乘得到类别置信度，最后8个元素是边界框的`x,y,w,h`。张量的图如下所示：

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/yolo-tensor.gif)

# 网络训练
在训练之前，先在ImageNet上进行预训练，其与训练的分类模型采用GooLeNet的前20个卷积层，然后添加一个average-pool层和全连接层。预训练之后，在预训练得到的20层卷积层之上随机初始化4个卷积层和2个全连接层。由于检测任务一般需要更高清的图片，所以将网络的输入从224x224增加到了448x448。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/yolo-network.jpg)

# 损失函数
YOLO将目标检测看做回归问题，采用的是均方差损失函数。
>损失函数为：Loss=权重x坐标预测误差+含object的边界框置信预测误差+权重x不含object的边框置信预测误差+每个格子中类别预测误差
>首先要区分定位误差和分类误差，对于定位误差，即边界框坐标预测误差`\lambda_{coord}=5`,然后是包含边界框和不包含边界框的置信度预测误差`\lambda _{obj}=1`和`\lambda _{noobj}=0.5`。具体的公式如下：

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/yolo-loss.jpg)

上式的第一项是边界框中心坐标的误差项，且`l_{ij}^{obj}`指的是第i个单元格存在目标，且该单元格中的第j个边界框负责预测该目标；第二项是边界框的高与宽的误差项；第三项是包含目标的边界框的置信度误差项；第四项是不包含目标的边界框的置信度误差项；最后一项是包含目标的单元格的分类误差项，`l_i^{obj}`指的是第i个单元格存在目标。

# 优缺点
- 优点
    - YOLO采用一个CNN网络来检测，是单管道策略，其训练预测都是end-to-end，速度较快。
    - YOLO是对整个图片做卷积，所以在检测的时候有更大的视野，不容易对背景做误判。
    - YOLO的泛化能力强，迁移时，鲁棒性较好
- 缺点
    - 对小物体及邻近特征检测效果差：当一个小哥中出现多余两个小物体时，效果欠佳。
    - 图片进入网络前会先进行resize为`448*448`，降低速率。
    - 基础网络计算量较大，yolo-v2采用darknet-19进行加速。