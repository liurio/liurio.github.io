# 多GPU编程

CUDA支持多设备协同操作：

- 可以获得设备数量和设备信息
- 可以选择设备，执行相关操作
- 可以用一个设备访问另一个设备的全局内存
- 设备间的全局内存可以传输数据

# 基本操作

## 获得设备的数量

```c++
__host__ __device__ cudaError_t cudaGetDeviceCount(int *count)
```

## 获取设备参数

```C++
__host__ cudaError_t cudaGetDeviceProperties(cudaDeviceProp *prop,int device)
/*
	参数prop：指定设备的信息
	参数device：指定的设备号
*/
int deviceCount;
cudaGetDeviceCount(&deviceCount);
int device;
for(device=0;device<deviceCount;++device)
{
    cudaDeviceProp deviceProp;
    cudaGetDeviceProperties(&deviceProp,device);
    printf("device %d has compute capability %d.%d.\n",device,deviceProp.major,
           deviceProp.minor);
}
```

## 选择设备

指定当前使用的设备

```c++
__host__ cudaError_t cudaSetDevice(int device)
/*
	参数device：指定的设备号
*/
    
size_t size = 1024*sizeof(float);
cudaSetDevice(0); //选择0号设备
float* p0;
cudaMalloc(&p0,size);	//0号设备上分配内存
MyKernel<<<1000,128>>>(p0);	//0号设备上启动核函数

cudaSetDevice(1);
float* p1;
cudaMalloc(&p1,size);	//1号设备上分配内存
MyKernel<<<1000,128>>>(p1);	//1号设备上启动核函数
```

# 设备通信

- 判断设备间是否可以通信

```c++
__host__ cudaError_t cudaDeviceCanAccessPeer(int* canAccessPeer,int device,
                                             int peerDevice)
/*
	canAccessPeer:返回访问能力
	device：当前设备号
	peerDevice:被访问的设备号
*/
```

- 使当前设备能与目标设备通信

```c++
__host__ cudaError_t cudaDeviceEnablePeerAccess(int peerDevice,unsigned int flags)
/*
	peerDevice:目标设备
	flags：0
*/
```

- 释放点对点通信

```c++
__host__ cudaError_t cudaDeviceDisablePeerAccess(int peerDevice)
/*
	peerDevice:目标设备
*/
```

```c++
size_t size = 1024*sizeof(float);
cudaSetDevice(0); //选择0号设备
float* p0;
cudaMalloc(&p0,size);	//0号设备上分配内存
MyKernel<<<1000,128>>>(p0);	//0号设备上启动核函数
cudaSetDevice(1);
cudaDeviceEnablePeerAccess(1,0); 	//在设备1启动对设备0的点对点访问
MyKernel<<1000,128>>>(p0);	//在设备1启动核函数，但可以访问设备0的内存
```

- 设备间的拷贝

```c++
__host__ cudaError_t cudaMemcpyPeer(void* dst,int dstDevice,const void* src,
                                    int srcDevice,size_t count)
/*
	dst: 目标设备指针
	dstDevice：目标设备
	src：源设备指针
	srcDevice：源设备
	count：拷贝内存的大小
*/
```

```c++
size_t size = 1024*sizeof(float);
cudaSetDevice(0); //选择0号设备
float* p0;
cudaMalloc(&p0,size);	//0号设备上分配内存
MyKernel<<<1000,128>>>(p0);	//0号设备上启动核函数
cudaSetDevice(1);
cudaMemcpyPeer(p1,1,p0,0,size); p0->p1
MyKernel<<1000,128>>>(p0);	//在设备1启动核函数，但可以访问设备0的内存
```

# 计算--加法

```c++
int main()
{
    int ngpus;
	CHECK(cudaGetDeviceCount(&ngpus));
    cudaStream_t *stream = (cudaStream_t *)malloc(ngpus*sizeof(cudaStream_t));
    float **d_A = (float **)malloc(sizeof(float *)*ngpus);
    float **d_B = (float **)malloc(sizeof(float *)*ngpus);
    float **d_C = (float **)malloc(sizeof(float *)*ngpus);
    float **h_A = (float **)malloc(sizeof(float *)*ngpus);
    float **h_B = (float **)malloc(sizeof(float *)*ngpus);
    float **hostRef = (float **)malloc(sizeof(float *)*ngpus);
    float **gpuRef = (float **)malloc(sizeof(float *)*ngpus);
    
    for(int i=0;i<ngpus;i++)
    {
       	//轮流设置当前设备
        CHECK(cudaSetDevice(i));
        CHECK(cudaStreamCreate(&stream[i]));
        CHECK(cudaMalloc((void **)&d_A[i],iBytes));
        CHECK(cudaMalloc((void **)&d_B[i],iBytes));
        CHECK(cudaMalloc((void **)&d_C[i],iBytes));
        CHECK(cudaMallocHost((void **)&h_A[i],iBytes));
        CHECK(cudaMallocHost((void **)&h_B[i],iBytes));
        CHECK(cudaMallocHost((void **)&hostRef[i],iBytes));
        CHECK(cudaMallocHost((void **)&gpuRef[i],iBytes));
        
        //在当前设备传输数据
        CHECK(cudaMemcpyAsync(d_A[i],h_A[i],iBytes,cudaMemcpyHostToDevice,stream[i]));
        CHECK(cudaMemcpyAsync(d_B[i],h_B[i],iBytes,cudaMemcpyHostToDevice,stream[i]));
        
        //在当前设备做加法运算
        iKernel<<<grid,block,0,stream[i]>>>(d_A[i],d_B[i],d_C[i],iSize);
        CHECK(cudaMemcpyAsync(gpuRef[i],d_C[i],iBytes,
                              cudaMemcpyDeviceToHost,stream[i]));
        
        CHECK(cudaFree(d_A[i]));
        CHECK(cudaFree(d_B[i]));
        CHECK(cudaFree(d_C[i]));
        CHECK(cudaFreeHost(h_A[i]));
        CHECK(cudaFreeHost(h_B[i]));
        CHECK(cudaFreeHost(hostRef[i]));
        CHECK(cudaFreeHost(gpuRef[i]));
        
        //释放流
        CHECK(cudaStreamDestroy(stream[i]));
        CHECK(cudaDeviceReset());
    }
}

```

