# 简介

GPU被定义为协处理器，普遍适用于大量轻量线程并行运行。对于一般的GPU和CPU组合计算架构，CPU被称为主机，GPU被称为设备。设备端和主机端都有自己的片外板载内存芯片(其中设备端的片外内存被称为**全局内存**)。设备和主机通过标准扩展总线相连(PICE总线)。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/pice.jpg)

典型的cuda程序的执行流程如下：

- 1 分配host内存，并进行数据初始化
- 2 分配device内存，并从host将数据拷贝到device
- 3 调用CUDA的核函数在device上完成指定的运算
- 4 将device上的运算结果拷贝到host上
- 5 释放device和host上分配的内存

# GPU硬件结构

## 片上宏观

- 流处理簇SM
  - 执行单元SP，CUDA的核心，运算单元
  - 寄存器文件
  - 片上内存：L1和共享内存、常量内存
  - 线程调度器和调度单元
- GigaThread引擎：是一个全局调度器，用来分配线程块block到SM线程束调度器上
- L2缓存：SM访问全局内存的必要元件，被所有SM共享的存储单元
- 全局内存接口：采用GDDR接口与片外的内存芯片相连。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/gpu-construct.jpg)

### SM计算资源

- 执行单元SP：cuda核心，每个核心处理一个线程，完成取指令、完成指令、返回结果的流水线操作。并都有一个整数算数逻辑单元ALU和一个浮点运算单元FPU。
- 寄存器文件：用来存放各线程的操作数，线程切换的重要存储单元。
- 片上内存：L1缓存+共享内存等
- 线程调度器和调度单元：负责线程束上下文切换。每个线程调度器调度32个核心和32个线程，这32个线程是一个线程束。
- 加载/存储单元（LD/ST单元）：允许每个时钟周期内有16个线程（线程束的一半）从源地址取数据以及将结果放回目的地址。
- 特殊功能单元（SFU）：执行固有指令，如正弦、余弦、平方根和插值。每个SFU在每个时钟周期内的每个线程上执行一个固有指令。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/gpu-sm.jpg)

# GPU内存模型

GPU内存设备主要有：

- 寄存器：CUDA核心的操作数来自寄存器，访问速度最快，方便线程切换。
- 片上内存：常量内存、L1缓存、常量内存
- 二级缓存：SM通过L2访问全局内存
- 全局内存：GPU的片外板载内存

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/gpu-save.jpg)

## 共享内存

利用共享内存可以缓存全局内存的数据，因为共享内存属于片上存储器，访问速度极快。共享内存属于SM资源，只能被调集到SM上的Block所利用(没有被调集到SM的Block不分配共享内存)。而共享内存又只能在每个block内部进行数据交换，block间不能交换。

```c
    __shared__ int tile[][]
```

利用共享内存来婚车全局内存数据，可以减少对全局内存的频繁操作，减少访问延迟。

## 常量内存

常量内存是只读内存，需要用到**const**关键字，常量内存其实只是全局内存的一种虚拟地址形式，并没有特殊保留的常量内存块。**常量内存有两个特性：一个是高速缓存，另一个是它支持将单个值广播到线程束中的每个线程。**，值得注意的，**对于那些数据不太集中或数据重用率不高的内存访问，不适合用常量内存。但是当多个线程读取相同的地址时，可以极大提高性能。**

```C++
    const int data = 0x55555555;
    int d = data;
```

常量内存的最大限制时64K，对常量内存数据更新时，需要在主机端调用**cudaMemcpyToSymbol()**函数。

```C++
    int cpu_data[512] = 0;
    __constant__ const int gpu_const_data[512];
    __device__ static int gpu_static_data[512];
    cudaMemcpyToSymbol(gpu_const_data, cpu_data, 512 * sizeof(int));
    cudaMemcpyToSymbol(gpu_static_data, cpu_data, 512 * sizeof(int));
```