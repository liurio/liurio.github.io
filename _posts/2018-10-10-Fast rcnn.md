Fast RCNN的主要贡献是对RCNN的加速。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/Fast%20RCNN%E5%8E%9F%E7%90%86.png)

### Fast RCNN的改进
> Fast RCNN的主要改进：
> 
> - 借鉴SPP的思路，提出简化版的**ROI池化层**(没有金字塔)，同时加入了候选框映射功能，使得网络**能够反向传播**，解决了SPP网络的整体训练问题。不再需要额外的硬盘来存储中间层的特征，梯度能够通过ROI池化层直接传播；
> - **多任务Loss层**
>     - **SoftmaxLoss替代了SVM**
>     - **SmoothL1Loss取代了Bounding box回归**
>     
>   将分类和边框回归合并(又一开创性的思路)，通过多任务Loss层进一步整个网络，统一了训练过程，提高了算法的精度。
> -  用RoI pooling层取代最后一层max pooling层，同时引入建议框信息，提取相应建议框特征
>
> - 全连接层通过**SVD**加速，分解全连接层的参数矩阵，压缩为两个更小规模很多的全连接层

### Fast RCNN的原理

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/Fast%20RCNN%E5%8E%9F%E7%90%86-%E6%B5%81%E7%A8%8B%E7%89%88.png)

> **步骤：**
> - 任意size图片输入CNN网络，经过若干卷积层与池化层，得到特征图；
> - 在任意size图片上采用Selective Search算法提取2000个候选框；
> - 根据原图中候选框到特征图的映射关系，在特征图中找到每个候选框对应的特征框(深度和特征图一致)，并在ROI池化层中将每个特征框池化到$h*w$的size；
> - 固定$$h*w$$大小的特征框经过全连接层得到固定大小的特征向量；
> - 上一步所得到的特征向量经由各自的全连接层(由SVD分解), 分别得到两个输出向量：一个是**softmax分类得分**，一个是**Bounding Box窗口回归**；
> - 利用窗口得分分别对每一类物体进行非极大值抑制剔除重叠候选框，最终得到每个类别中回归修正后得分最高的窗口；

### ROI池化

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/Fast%20RCNN%20ROI%E6%B1%A0%E5%8C%96.png)

每一个ROI都由一个四元组$$(r,c,h,w)$$组成，其中$(r,c)$表示左上角，而$$(h,w)$$表示高度和宽度。这一层使用最大池化(max pooling)将Rol区域转化为固定大小的$$H*W$$的特征图。

ROI最大池化将$$h*w$$的ROI窗口划分为$$h/H * w/W$$个子窗口网格，子窗口的大小是$$H*W$$, 然后将每个子窗口的值max pooling到相应的输出网格单元。这是SPP-Net的简化版，只有一层金字塔。

ROI POOL将每个候选区域均匀分成$$H*W$$块，对每块进行max pooling。将特征图上大小不一致的区域转变成大小一致的数据，送入下一层。

>- **ROI pooling layer的作用**：
>    - 是将image中rol定位到feature map中的batch
>    - 用一个单层的SPP layer将这个feature map >batch下采样为大小固定的feature再传入全连接层。即ROI pooling layer统一相同的大小 -> >全连接层的feature vector -> 提取一个固定维度的特征表示

### Fine-tuning for detection 检测中的微调
Fast R-CNN用反向传播训练所有网络权重。首先，作者说明了为什么SPPnet无法更新空间金字塔池化层之前的层的权重：当每个训练样本（即RoI）来自不同的图像时，通过SPP层的反向传播非常低效。低效源于每个RoI可能具有非常大的感受野（接收区），通常包括整个输入图像。由于正向传播必须处理整个感受野，训练输入是非常大（通常是整个图像）。

在Fast RCNN训练中，随机梯度下降（SGD）小批量计算被分级采样，首先随机取样N张图片，然后每张图片取样 R / N 个RoIs。关键的是，来自相同图像的RoI在向前和向后传播中共享计算和内存。

除了分层采样，Fast R-CNN使用了一个精简的训练过程，一次微调中联合优化的softmax分类器和bbox回归，而不是在三个独立的阶段训练softmax分类器，SVM和回归因子。看似这一步，实际包括了**多任务损失(multi-task loss)、小批量取数(mini-batch sampling)、ROI layer的反向传播、SGD超参数**。
#### Muti-task loss
Fast R-CNN网络分类损失和回归损失如下图所示【仅针对一个RoI即一类物体说明】，黄色框表示训练数据，绿色框表示输入目标：

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/multi-task-fast-rcnn.png)

-cls_score层用于分类，输出K+1维数组p，表示属于K类物体和背景的概率； 
-bbox_predict层用于调整候选区域位置，输出4*K维数组，也就是说对于每个类别都会训练一个单独的回归器；

- **整个的回归损失loss**：
>​	$$L(p,u,t^u,v) = L_{cls}(p,u)+\lambda [u>=1]L_{loc}(t^u,v)$$
>
>​	第一项是分类损失，$L_{cls}(p,u)=-log(p_u)$对于分类loss，是一个N+1路的softmax输出，其中的N是类别个数，1是背景。

第二项是回归损失，对于每个类别都会训练一个单独的regressor，评估回归损失代价就是比较真实分类 u 对应的预测平移缩放参数和真实平移缩放参数的差距：
$$L_{loc}(t^u,v)=\sum_{i \in {x,y,w,h}}{smooth_{L_1}(t_i^u-v_i)}$$其中，$$v=(v_x,v_y,v_w,v_h)$$是真实平移的缩放参数。$$t^u$$是对u重新预测bbox回归平移缩放的参数$$t^u=(t_x^u,t_y^u,t_w^u,t_h^u)$$
这里的损失不是L2损失函数，而是smooth L1损失函数，对于离群点不敏感，因为有L2损失的训练可能需要仔细调整学习率，以防止爆炸梯度（控制梯度的量级使得训练时不容易跑飞）。
公式如下：

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/smooth.png)

超参数$\lambda$是用来控制两个损失函数平衡的。
#### 4.2 Mini-batch sampling
作者从对象建议框（object proposal）中选择25%的RoI，这些RoI与ground-truth bbox边界框至少有0.5的部分交叉重叠，也就是正样本，即 u >= 1。其余的RoI选那些IoU重叠区间在[0.1,0.5)的，作为负样本，即 u = 0，大约为75%。之所以选择负样本需要大于0.1的阈值是因为使用启发式的hard example mining（低于0.1的IoU作为难例挖掘的启发式）。在训练期间，图像有0.5的概率水平翻转。

#### 4.3 SGD超参数选择
除了修改增加的层，原有的层参数已经通过预训练方式初始化：
用于分类的全连接层以均值为0、标准差为0.01的高斯分布初始化；
用于回归的全连接层以均值为0、标准差为0.001的高斯分布初始化，偏置都初始化为0； 

针对PASCAL VOC 2007和2012训练集，前30k次迭代全局学习率为0.001，每层权重学习率为1倍，偏置学习率为2倍，后10k次迭代全局学习率更新为0.0001；
动量设置为0.9，权重衰减设置为0.0005。

#### 4.4 ROI layer的反向传播
RoI池化层如何进行反向求导训练？：[https://blog.csdn.net/WoPawn/article/details/52463853?locationNum=5](https://blog.csdn.net/WoPawn/article/details/52463853?locationNum=5)