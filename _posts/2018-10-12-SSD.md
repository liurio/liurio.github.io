采用的是VGG-16网络，其网络结构见网址：[http://ethereon.github.io/netscope/#/preset/vgg-16](http://ethereon.github.io/netscope/#/preset/vgg-16 ) 

code [https://github.com/balancap/SSD-Tensorflow](https://github.com/balancap/SSD-Tensorflow  )  

  [https://github.com/xiaohu2015/DeepLearning_tutorials/tree/master/ObjectDetections/SSD]( https://github.com/xiaohu2015/DeepLearning_tutorials/tree/master/ObjectDetections/SSD)

目标检测-SSD原理与实现 [https://zhuanlan.zhihu.com/p/33544892](https://zhuanlan.zhihu.com/p/33544892)

源码分析 [https://blog.csdn.net/qq1483661204/article/details/79776065]( https://blog.csdn.net/qq1483661204/article/details/79776065)

SSD的改进
- 从YOLO中继承了将detection转化为regression的思路，同时一次即可完成网络训练。
- 基于Faster RCNN中的anchor，提出了相似的prior box。
- 加入基于特征金字塔(Pyramidal Feature Hierarchy)的检测方式，相当于半个FPN思路。

## 1. SSD网络结构
![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-net.png)

该图是SSD 300的网络结构图。可以看到YOLO在卷积层后接全连接层，即检测时只利用了最高层feature maps(包括Faster RCNN也是如此)；而SSD采用了特征金字塔结构进行检测，即检测时利用了conv4-3,conv-7(fc7)，conv6-2,conv7-2,conv8-2,conv9-2这些大小不同的feature maps，在多个feature maps上同时进行softmax分类和回归。

在这个SSD网络中，将VGG16的最后两个全连接层改成卷积层，并随后增加了4个卷积层来构造网络，对其中5中不同卷积层的输出(feature map)分别用两个不同的`3*3`的卷积核进行卷积，一个输出分类用的confidence，每个default box生成21个类别；另一个用来输出回归用的localization，每个default box生成4个坐标值；

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-pfh.jpg)

### 2. prior box
在SSD中引入了Prior box，与faster RCNN中的anchor很类似，就是一些目标的候选框，后续通过softmax分类+bounding box回归获取真实目标的位置。
#### 2.1 名词解释
- **feature map cell**：feature map中的每个小格子
- **default box**:在feature map的每个小格子cell上都有一些列固定大小的box。是一种概念
- **prior box**：实际中选择的default box(每个feature map cell并不是所有的default box都取)。是一种实际的选取。


#### 2.2 prior max的生成规则
>`aspect_ratio=(1,2,3,1/2,1/3)`

步骤：
- 先以feature map cell的中点为中心(offset=0.5)，生成一系列同心的prior box
- 先生成两个正方形(`aspect_ratio=1`),最小边长是`min{\_}size`,最大边长是`\sqrt{min{\_}size * max{\_}size}`
- 再生成四个长方形，对应的长宽分别为: `\sqrt{aspect_ratio}*min_size`和`\frac{1}{\sqrt{aspect_ratio}}*min_size`，分别对应着`aspect_ratio=2,3,1/2,1/3`

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-prior-box.jpg)

- 而每个feature map对应的prior box的`min{\_}size`和`max{\_}size` 由以下公式确定，公式中的m是feature map的数量(SSD 300中m=6)
  ![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-1.png)

#### 2.3 对应的各种参数

| feature map | out_size | prior_box_num | total_num | min_size | max_size |
| ----------- | -------- | ------------- | --------- | -------- | -------- |
| conv4-3     | 38X38    | 4             | 5776      | 30       | 60       |
| fc7         | 19X19    | 6             | 2166      | 60       | 111      |
| conv5-2     | 10X10    | 6             | 600       | 111      | 162      |
| conv7-2     | 5X5      | 6             | 150       | 162      | 213      |
| conv8-2     | 3X3      | 6             | 36        | 213      | 264      |
| conv9-2     | 1X1      | 4             | 4(总8732) | 264      | 315      |

从表格中可以看出，SSD使低层feature map检测小目标，使用高层feature map检测大目标，这也应该是SSD的突出贡献了。

六种不同的特征图用来检测不同的尺度：conv4_3,conv7,conv8_2,conv9_2,conv10_2,conv11_2，其大小分别为(38x38),(19x19),(10x10),(5x5),(3x3),(1x1)。先验框的尺度，遵循一个线性递归的原则：随着特征图大小的降低，先验框尺度线性增加；各个特征图的尺度分别为(30,60,111,162,213,264)

#### 2.4 prior box使用输出
![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-pipline.jpg)

假设每个feature map cell上有k个default box，那么对每个default box都需要预测`c`个类别的score和4个offset，那么如果一个feature map大小时`m*n`，那么也就是有`m*n`个feature map cell，那么这个feature map就有`(c+4)*k*m*n`个输出。这些数字的含义：
>采用`3*3`的卷积核对该层的feature map卷积时，卷积核的个数包含两部分
>   - 经过一次batch norm+一次卷积后，数量`c*k*m*n`是confidence输出，表示每个default box的confidence，也就是类别的概率；SSD `c=21`
>   - 经过一次batch norm+一次卷积后，数量`4*k*m*n`是localization输出，表示每个default box回归的坐标。
>   - 生成了`2*4*k`大小的prior box，其中两个通道，分别存储4个点坐标和对应的4个variance。

#### 2.5 多个feature maps如何协调工作？
会通过Permute层、flatten层、concat层协调控制活动。
如下图所示的conv6-2的localization的`3*3`卷积核操作，卷积核个数是24(由于pad=1，所以卷积结果的map大小不变)：这里的permute层就是交换的作用，比如你卷积的维度是`32*24*19*19`，那么经过交换层后就变成`32*19*19*24`，顺序变了而已。而flatten层的作用是将`32*19*19*24`变为`32*8664`，32是batch_size的大小。经过上述两个过程后，对每一层的feature的处理就结束了。待所有的feature map都执行上述操作后，采用concat层，将结果合并，是通道合并不是数值相加。

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-detail.jpeg)

## 3. SSD训练过程
#### 3.1 正负样本
##### 匹配策略
>首先，寻找与每一个ground truth box有最大IOU的default box，这样就保证了每一个ground truth box都有一个唯一的prior box与之对应。

>SSD之后又将剩余还没有匹配的default box 与任意一个ground truth box尝试匹配，只要IOU大于一个阈值，就算匹配成功。

>显然，匹配成功的是prior box就是正样本，不成功的就是负样本。

##### Hard negative mining
一般来说，候选负样本集的数目要远大于候选正样本集的数目，会造成正负样本集不平衡，训练时难以收敛。

所以SSD在训练的时候会根据confidence score进行排序default box，然后挑选出confidence score高的box进行训练，控制`positive:negative=1:3`

例子：假设在这8732个prior box里，有P个属于正样本集，8732-P个属于负样本集；将prior box根据confidence score进行排序后选择较高的M个prior box。如果候选正样本集有a个不在这M里，那么就把这a个从候选正样本集中删除；如果8732-P个候选负样本集中有b个在M里，那么就将这b个候选负样本作为负样本。

##### 数据增广 data augmentation
有如下几种选择方式：
- 使用原始的图像
- 采样一个batch，与物体之间的最小IOU为0.1,0.3,0.5,0.7,0.9
- 随机的采样一个patch
  采样的patch是原始图像大小比例是`[0.1,1]`，aspect ratio在`0.5,2`之间。当ground truth box的中心在采样的patch中时，保留重叠部分；在这些采样步骤完成之后，每一个采样的patch被resize到固定的大小，并且以概率0.5随机水平翻转。

#### 3.2 损失函数

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-loss.jpeg)

从上图公式中可以看出，损失函数分为confidence loss和location loss两部分，其中N是匹配到ground truth box的prior box的数量；而`\alpha `参数用于调整confidence loss和location loss之间的比例。默认为1。
- SSD中的confidence loss是典型的softmax loss：
![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-2.png)

其中`x_{ij}^p=\{0,1\}`代表第i个prior box匹配到了第j个类别为p的ground truth box；
- 而location loss 是典型的smooth L1 loss
![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-3.png)

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/smooth.png)

### 4 SSD预测过程
预测过程比较简单，对于每个预选框，首先根据类别置信度确定其类别(置信度最大者)与置信度值，并过滤掉属于背景的预选框。然后根据置信度阈值(0.5)过滤掉阈值较低的预选框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数(解码后一般还需要做clip，为了防止预测框位置超出图片)。解码之后，一般需要根据置信度进行降序排列，然后仅保留top-k个预选框。最后就是进行NMS算法，顾虑掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果。

### 5 边界框的编码encode与解码decode
![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-6.png)

所谓编码过程就是获取边界框预测值的过程：

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-4.png)

所谓解码就是从预测值中获取到真实位置：

![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/ssd-5.png)