---
logout: post
title: hive两个大表关联的处理办法
tags: [hive,all]
---

场景：一个表是集团行为日志埋点表，大小多于700TB，按天分区，每天大约几亿条数据，另一个是pv流量表，大约300TB左右，按天分区，每天大约7000万条数据。两个表直接join的话，执行时间超过1个小时，还没执行完，直接kill。需要优化！

##处理步骤

### 建立桶表

#### 建立小表

```sql
create table table1(uid int comments '用户id',name string comment '用户名称')
partitioned by(d string)
clustered by(uid) sorted by(uid) into 10 buckets;
```

####建立大表

```sql
create table table2(uid int comment '用户id',email string comment '用户邮箱')
partitioned by(d string)
clustered by(uid) sorted by(uid) into 10 buckets;
```

需要注意几点

> - 两个表关联键为uid，需要用uid分桶做排序，并且小表的分桶数是大表分桶数的倍数。
> - 对于map端连接的情况，两个表以相同方式划分桶。处理左边表内某个桶的 mapper知道右边表内相匹配的行在对应的桶内。因此，mapper只需要获取那个桶 (这只是右边表内存储数据的一小部分)即可进行连接。这一优化方法并不一定要求 两个表必须桶的个数相同，两个表的桶个数是倍数关系也可以
> - 桶中的数据可以根据一个或多个列另外进行排序。由于这样对每个桶的连接变成了高效的归并排序(merge-sort), 因此可以进一步提升map端连接的效率

### 启用桶表

```sql
set hive.enforce.bucketing = true;
```

### 往桶表中插入数据

```sql
/**表1*/
insert overwrite table table1 partition (d='2022-04-22')
select uid,name from tableA where d='2022-04-22';
/**表2*/
insert overwrite table table2 partition (d='2022-04-22')
select uid,email from tableB where d='2022-04-22';
```

### 设置SMB join (Sort Merge Bucket Map join)的参数

```sql
set hive.optimize.bucketmapjoin = true;
set hive.optimize.bucketmapjoin.sortedmerge = true;
set hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
```

### 查询

```sql
select count(1)
from (select d,uid,name from table1 where d='2022-04-22') a 
join (select d,uid,email from table2 where d='2022-04-22') b
on a.d=b.d and a.uid=b.uid
```

## bucket map join 和 SMB join 的区别

bucket map join

> - 一个表的bucket数是另一个表bucket的整数倍
> - bucket列==join列
> - 必须应用在map join场景中

SMB join (针对bucket map join的优化)

> - 小表的bucket数=大表bucket数
> - bucket列 = join列 = sort 列
> - 必须是应用在bucket map join场景中