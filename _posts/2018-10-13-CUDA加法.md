# CUDA加法模型
## 获取索引

- 只有线程块
  ![image](https://raw.githubusercontent.com/liurio/deep_learning/master/img/gpu-threadIdx.png)
- 线程网格
```c
    在线程网格下，
    dim3 threads_square(16,8);
    dim3 threads_square(2,2);
    kernel_function<<<threads_square,threads_square>>>(){

        // idx 可以简单的理解为二维空间上x的绝对偏移量， 
        // threadIdx.x则是相对偏移,也就是在一个线程块中的x的偏移量，线程在某块的第几个位置
        const unsighned int idx=(blockIdx.x*blockDim.x)+threadIdx.x;

        // idy 可以简单的理解为二维空间上y的绝对偏移量， 
        // threadIdx.y则是相对偏移,也就是在一个线程块中的y的偏移量
        const unsighned int idy=(blockIdx.y*blockDim.y)+threadIdx.y;
        const unsighned int thread_idx=(gridDim.x*blockDim.x)*idy+idx;
    }
```
其实这个索引有点类似矩阵索引，先确定x方向上的绝对偏移量idx，为什么会有绝对偏移与相对偏移呢，因为整个大的线程网格是由很多网格组成的，同时每个网格里又是二维的，而threadIdx.x是在指该网格内的偏移，所以x的绝对偏移量是网格的x轴方向宽度blockDim.x乘于网格的偏移blockIdx.x再加上threadIdx.x。同理idy也是这么计算。
然后thread_idx也是相似的原理，y的绝对偏移量乘以x轴上线程数目(gridDim.x*blockDim.x)，再加上x轴本身自己的绝对偏移，就可以得到正确的索引了。

## grid 1-dim, block 1-dim

```C++
int main()
{
    int N=1<<20;
    int nBytes = N*sizeof(float);
    
    //申请托管内存
    float *x,*y,*z;
    cudaMallocManged((void **)&x,nBytes);
    cudaMallocManged((void **)&y,nBytes);
    cudaMallocManged((void **)&z,nBytes);
    
    //初始化数据
    for(int i=0;i<N;i++)
    {
        x[i]=10.0;
        y[i]=20.0;
    }
    
    //定义核函数
    dim3 block(256);
    dim3 grid((N+block.x-1)/block.x);
    add_1dim<<<grid,block>>>(x,y,z,N);
    
    //同步数据
    cudaDeviceSynchronize();
    
    //检查输出结果
    float maxError = 0.0;
	for(int i=0;i<N;i++)
	{
		maxError = fmax(maxError,fabs(z[i]-30.0));
	}
	cout<<"max error: "<<maxError<<endl;
    
    //释放空间
	cudaFree(x);
	cudaFree(y);
	cudaFree(z);
	
	return 0;
}

__global__ void add_1dim(float *x,float *y, float *z, int N)
{
    int index = blockIdx.x*blockDim.x+threadIdx.x;
    int stride = blockDim.x*gridDim.x;
    for(int i=0;i<N;i+=stride)
    {
        z[i]=x[i]+y[i];
    }
}
```

## grid 2-dim, block 1-dim

```C++
int main()
{
    ...
    dim3 block(256);
    dim3 grid((Nx+block.x-1)/block.x,Ny);
    add_dim<<<grid,block>>>(x,y,z,Nx,Ny);
    ...
}

__global__ void add_dim(float *x,float *y, float *z,int Nx,int Ny)
{
    int ix = blockIdx.x * blockDim.x + threadIdx.x; --第一维的grid
	int iy = threadIdx.y; -- 第二维的grid
    int index =iy * (gridDim.x*blockDim.x) + ix;
    if(ix<Nx && iy<Ny)
    	z[index] = x[index] + y[index];
}
```



## grid 2-dim, block 2-dim

```C++
int main()
{
    ...
    dim3 block(256,256);
    dim3 grid((Nx+block.x-1)/block.x,(Ny+block.y-1)/block.y);
    add_dim<<<grid,block>>>(x,y,z,Nx,Ny);
    ...
}

__global__ void add_dim(float *x,float *y, float *z,int Nx,int Ny)
{
    int ix = blockIdx.x * blockDim.x + threadIdx.x; --第一维的grid
	int iy = blockIdx.y * blockDim.y + threadIdx.y; -- 第二维的grid
    int index =iy * (gridDim.x*blockDim.x) + ix;
    if(ix<Nx && iy<Ny)
    	z[index] = x[index] + y[index];
}
```

