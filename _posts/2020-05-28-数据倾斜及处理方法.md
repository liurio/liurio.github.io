---
logout: post
title: 数据倾斜及处理方法
tags: [hive,all]
---

### 什么是数据倾斜？

数据倾斜就是我们在计算数据的时候，数据的分散度不够，导致大量的数据集中到了集群中的一台或者几台机器上计算，而集群中的其他节点空闲。这些倾斜了的数据的计算速度远远低于平均计算速度，导致整个计算过程过慢。比如reduce的时候卡在99%，出不来结果。

### 数据倾斜产生的原因？

- key分布不均匀
- 业务数据本身的特性
- 建表时考虑不周
- 某些sql语句本身存在数据倾斜

### 如何定位数据倾斜？

- 只发生在shuffle阶段，可能由算子distinct、groupByKey、reduceByKey、join、reparation等引起的。
- 通过ui来看，看具体哪个reduce耗时太长。

### 解决方案

- 增加JVM内存
- 增加reduce个数(可能只有一个reduce在处理)
- 重新设计key
- 使用combiner合并(相当于local reduce操作)，shuffle之前的预处理
- 参数调节
- 通过sql语句调节

#### 参数调节

1. groupby引起的数据倾斜。`hive.groupby.skewindata=true;`
2. join产生的数据倾斜。`hive.optimize.skewjoin=true;`

#### sql语句调节

**如何join**

> 关于驱动表的选取，选用join key分布最均匀的表作为驱动表。做好列裁剪和filter操作，以达到两表做join的时候，数据量相对变小的效果

**大小表join**

> 使用map join让小的维度表，先进入内存。在map端完成reduce。

大表join大表

> 把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后不影响最终结果。

**count distinct大量相同特殊值**

> count distinct时，将值为空的情况单独处理，如果是计算count distinct，可以不用处理，直接过滤，在最后结果中加1。如果还有其他计算，需要进行group by，可以先将值为空的记录单独处理，再和其他计算结果进行union。

**group by维度过小**

> 采用sum() group by的方式代替count(distinct)完成计算。

**特殊情况特殊处理**

> 在业务逻辑优化效果的不大情况下，有些时候是可以将倾斜的数据单独拿出来处理。最后union回去。

### 典型的业务场景

#### 空值产生的倾斜

对空的id赋予拼接一个随机值。

```sql
select *  
  from log a  
  left outer join users b  
  on case when a.user_id is null then concat(‘hive’,rand() ) else a.user_id end = b.user_id;  
```

#### 不同类型关联时产生倾斜

类型不匹配时，会导致右端的数据全部分到一个reduce上。解决：cast转类型

```sql
select * from users a  
  left outer join logs b  
  on a.usr_id = cast(b.user_id as string)  
```

#### 小表不大也不小，怎么样map join解决倾斜？

可以把小表分成拆分来join

```sql
select /*+mapjoin(x)*/* from log a  
  left outer join (  
    select  /*+mapjoin(c)*/d.*  
      from ( select distinct user_id from log ) c  
      join users d  
      on c.user_id = d.user_id  
    ) x  
  on a.user_id = b.user_id;
```

#### 大表join大表

把左表的未关联记录的key尽可能打散，使这些数据能够均匀分配到多个reduce上。

```sql
select a.id
from trackinfo a  
left outer join pm_info b  
on (  
    case when (a.ext_field7 is not null  
        andlength(a.ext_field7) > 0  
        anda.ext_field7 rlike '^[0-9]+$')  
    then  
        cast(a.ext_field7as bigint)  
    else  
        cast(ceiling(rand() * -65535)as bigint)  
    end= b.id  
)  
```

