---
logout: post
title: Flink生产消费模型
tags: [flink,all]
---

![img](https://gitee.com/liurio/image_save/raw/master/flink/%E7%94%9F%E6%88%90%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%9E%8B.jpg)

大致思想：

1. map产生数据存到缓冲RP1, 对应步骤1
2. 通过akka访问JobManager，查看消费端，对应步骤2
3. JobManager再查看消费端是否做好准备，对应3a,3b
4. 准备好后，消费端向RP1(生产端)发送传输数据请求，对应4a,4b
5. RP1开始具体往TaskManager中的消费端传送数据，对应5a,5b (如果是跨节点时，需要用Netty传输)

![img](https://gitee.com/liurio/image_save/raw/master/flink/%E7%94%9F%E6%88%90%E6%B6%88%E8%B4%B9%E9%80%9A%E4%BF%A1%E5%9B%BE.jpg)

该图是具体的通信运行过程，主要包括三个部件：将记录写入结果分区的写入器、将数据从输入网关中读取并反序列化转化为记录的读取器、周旋在记录和二进制的Buffer数据之间对数据表示进行转换的序列化器。将整个过程为分以下5个步骤：序列化阶段、结果分区(ResultPartition)生产阶段、通信传输阶段、InputGate消费阶段、反序列化阶段。

运行的过程如下：最初map生产数据记录，这些记录传送给RecordWriter对象，该对象创建的时候，会根据通道的数量创建相对应的序列化器，而且每个通道都有一个序列化器，这些序列化器的类型是SpanningRecordSerializer，它是一种跨内存段的序列化器，其实现是借助于中间缓冲区来缓存序列化后的数据，然后再往真正的目标Buffer(真正的Buffer存储在ResultSubPartition中)中写入。

当RecordWriter对象和序列化器创建好之后，一个ChannelSelector就会根据相应的分区策略(比如broadcast、KeyGroupStreamPartitioner等)来选择合适的序列化器，序列化器将数据记录转化为二进制的形式，将他们放入大小合适的中间缓冲区buffer，然后这时候创建的ResultPartitionWriter对象，调用方法，就会从把中间缓冲区的数据，传输到相应的ResultSubPartition(Buffer真正存储在这里)。当首个buffer写入之后，ResultSubPartition会变成可被访问的状态，然后通知JobManager，JobManager会查找ExecutionGraph的ResultSubPartition的消费者(假如TaskManager2中的InputGate需要消费该ResultSubPartition)，然后JobManager就会向所有的消费者发送可以消费的消息，当TaskManager2收到消费数据可以被访问的消息后，就会向TaskManager1的ResultSubPartition发送一个可以传输数据的请求，当TaskManager1中的RSP收到请求后，通过Netty进行数据的传输，当InputChannel收到数据之后，进入InputGate，反序列化器RecordDeserializer会将收到的buffer数据进行反序列化，然后传给reduce。

在TaskManager启动创建之后，NetworkEnvironment也会被创建，它是TaskManager进行网络通信的主对象，主要用于跟踪中间结果并负责所有的数据交换。该类中有个registerTask方法，该方法会为每个ResultSubPartition以及之后的InputChannel创建Buffer缓冲区。并且TaskManager在启动后会向JobManager注册，随后NetworkEnvironment的associateWithTaskManagerAndJobManager方法会得到调用，在其中所有的辅助部件都会得到实例化：比如connectionManager(连接管理器，用于管理本地（远程）通信连接)。

### 序列化阶段和结果分区生产阶段

![img](https://gitee.com/liurio/image_save/raw/master/flink/%E5%BA%8F%E5%88%97%E5%8C%96%E9%98%B6%E6%AE%B5%E5%92%8C%E7%BB%93%E6%9E%9C%E5%88%86%E5%8C%BA%E7%94%9F%E4%BA%A7%E9%98%B6%E6%AE%B5.jpg)

为了使得记录能够顺利被写入Buffer， Flink提供了记录序列化器（RecordSerializer）。RecordSerializer，作为一个接口，SpanningRecordSerializer是其唯一的实现。它是一种支持跨内存段的序列化器，其实现借助于中间缓冲区来缓存序列化后的数据，然后再往真正的目标Buffer(真正的buffer是存储在ResultSubPartition中)里写。

```java
public SpanningRecordSerializer() {
    this.serializationBuffer = new DataOutputSerializer(128);
    this.lengthBuffer = ByteBuffer.allocate(4);
    this.lengthBuffer.order(ByteOrder.BIG_ENDIAN);
    this.dataBuffer = this.serializationBuffer.wrapAsByteBuffer();
    this.lengthBuffer.position(4);
}
public ByteBuffer wrapAsByteBuffer() {
    this.wrapper.position(0);
    this.wrapper.limit(this.position);
    return this.wrapper;
}
```

如上图所示，当写入器RecordWriter开始创建的时候，会根据通道的数量创建相同数量的序列化器，即每个通道都有一个默认为SpanningRecordSerializer的序列化器，所以一个ChannelSelector就会根据相应的分区策略(比如broadcast、KeyGroupStreamPartitioner等)来选择合适的序列化器(对应相应的通道)，然后借助序列化器SpanningRecordSerializer内部的addRecord和setNextBuffer两个函数，完成具体的序列化操作，其中setNextBuffer方法的主要作用是重新初始化一个新的Buffer作为目标Buffer并刷出剩余数据。而addRecord方法则主要用于进行真正的序列化操作。同时会将序列化后的数据存储到中间缓冲buffer中，然后调用emit()函数，该函数内部有sendToTarget()，

```java
private void sendToTarget(T record, int targetChannel) throws IOException, InterruptedException {
    RecordSerializer<T> serializer = serializers[targetChannel];
    synchronized (serializer) {
        SerializationResult result = serializer.addRecord(record);
        while (result.isFullBuffer()) {
            Buffer buffer = serializer.getCurrentBuffer();
            if (buffer != null) {
                numBytesOut.inc(buffer.getSize());
                writeAndClearBuffer(buffer, targetChannel, serializer);		
                if (result.isFullRecord()) {
                    break;
                }
            } else {
                buffer = targetPartition.getBufferProvider().requestBufferBlocking();
                result = serializer.setNextBuffer(buffer);
            }
        }
    }
```

在sendToTarget()函数内，writeAndClearBuffer()方法的主要作用就是具体的发送给指定的ResultSubPartition，在writeAndClearBuffer()函数中，会通过写入器ResultPartitionWriter将buffer记录写入到ResultSubPartition，具体的加入代码如下：

```java
public void add(Buffer buffer, int subpartitionIndex) throws IOException {
    boolean success = false;
    try {
        checkInProduceState();
        final ResultSubpartition subpartition = subpartitions[subpartitionIndex];
        synchronized (subpartition) {
            success = subpartition.add(buffer);
            totalNumberOfBuffers++;
            totalNumberOfBytes += buffer.getSize();
        }
    }
    finally {
        if (success) {notifyPipelinedConsumers();}
        else {buffer.recycle();}
    }
}
```

到此，写入过程结束。当记录开始写入且存储到ResultSubPartition的buffer后，此时会执行notifyPipelinedConsumers()函数，使该子分区的数据变为可访问状态，来通知消费者消费数据。

### 通知消费者消费

![img](https://gitee.com/liurio/image_save/raw/master/flink/%E9%80%9A%E7%9F%A5%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9.jpg)

当ResultSubPartition子分区内的数据变成可访问状态时，会调用notifyPipelinedConsumers来通知消费者消费，然后ActorGatewayResultPartitionConsumableNotifier类实现了上述的抽象方法，代码如下：

```java
public void notifyPartitionConsumable(JobID jobId, final ResultPartitionID partitionId, final TaskActions taskActions) {
	JobManagerMessages.ScheduleOrUpdateConsumers msg = new
 								JobManagerMessages.ScheduleOrUpdateConsumers(jobId, partitionId);
Future<Object> futureResponse = jobManager.ask(msg, jobManagerMessageTimeout);
		futureResponse.onFailure(new OnFailure() {
			public void onFailure(Throwable failure) {
				taskActions.failExternally(new RuntimeException("Could not notify JobManager to schedule or update consumers", failure));
			}
		}, executionContext);
	}
```

该函数的主要作用是JobManager获取消费消息，然后通过akka通信机制的ask函数，将封装好的消息msg发送给TaskManager，由于是ask模式，所以需要有应答(另外一种，是tell，该模式不需要响应应答)。下面具体深入ScheduleOrUpdateConsumers函数，该函数的作用是根据ExecutionGraph获取生产ResultSubPartition的指定消费者，并且更新消费者中的信息。

首先，会调用中的得到，然后调用类中并且根据得到IntermediateResultPartition的所有出边集合，然后调用Execution类中的scheduleOrUpdateConsumers方法，在该方法内会根据生产者分区传递过来的ExecutionAttemptId来具体定位到某个(或者某几个)消费者，当确定消费者之后，并且把信息封装在PartitionInfo中，会调用sendUpdatePartitionInfoRpcCall函数来具体通知消费者并且更新消费者的信息，并且同时向生产子分区做出响应。

```java
private void sendUpdatePartitionInfoRpcCall(
	final Iterable<PartitionInfo> partitionInfos) {
	final SimpleSlot slot = assignedResource;
	if (slot != null) {
		final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway();
		final TaskManagerLocation taskManagerLocation = slot.getTaskManagerLocation();
		CompletableFuture<Acknowledge> updatePartitionsResultFuture =
 						taskManagerGateway.updatePartitions(attemptId, partitionInfos, timeout);
		updatePartitionsResultFuture.whenCompleteAsync(
			(ack, failure) -> {
					if (failure != null) {			
						. . . . . . 
```

通过slot. getTaskManagerGateway获取到具体的InputGate消费端，然后调用updatePartitions获取partitionInfo从而更新具体消费端的信息，并把信息重新封装在updatePartitionInfoMessage消息中。

```java
public CompletableFuture<Acknowledge> updatePartitions(ExecutionAttemptID executionAttemptID, 
Iterable<PartitionInfo> partitionInfos, Time timeout) {
		TaskMessages.UpdatePartitionInfo updatePartitionInfoMessage = new 
				TaskMessages.UpdateTaskMultiplePartitionInfos(executionAttemptID,partitionInfos);
		scala.concurrent.Future<Acknowledge> updatePartitionsResult = actorGateway.ask(
			updatePartitionInfoMessage,
			new FiniteDuration(timeout.getSize(), timeout.getUnit()))
			.mapTo(ClassTag$.MODULE$.<Acknowledge>apply(Acknowledge.class));
		return FutureUtils.toJava(updatePartitionsResult);
	}
```

当消费端的信息封装好之后，会调用akka通信机制，然后把信息传递给TaskManager，传递结束后，会调用最后的toJava方法，TaskManager中该方法内有个akka的onComplete方法向JobManager做出响应(即做出ask提出的响应)，之后JobManager又会调用akka中的whenCompleteAsync函数去向生产子分区做出响应(即做出ask提出的响应)。

### 消费者做具体消费

![img](https://gitee.com/liurio/image_save/raw/master/flink/%E6%B6%88%E8%B4%B9%E8%80%85%E5%81%9A%E5%85%B7%E4%BD%93%E6%B6%88%E8%B4%B9.jpg)

当TaskManager收到由JobManager的发送的消息请求后，会创建InputGate对象，Flink提供了两种InputGate的实现，分别是SingleInputGate和UnionInputGate，SingleInputGate是消费ResultPartition的实体，在create()方法中会创建InputGate以及相应的InputChannel，InputChannel的数目和消费分区的数目是一致的，然后每一个InputChannel会通过getConsumedPartitionLocation()方法来确定其消费来源(即某个或某几个对应的ResultSubPartition)，同时会判断该分区的位置(是local还是remote)，如果是local的话，就会调用LocalInputChannel来创建具体的inputChannel；如果是remote，对调用RemoteInputChannel来创建具体的inputChannel；

​       接下来就会具体获取的来消费，具体的消费函数调用，

```java
public BufferOrEvent getNextBufferOrEvent() throws IOException, InterruptedException {
		requestPartitions();
		synchronized (inputChannelsWithData) {
			while (inputChannelsWithData.size() == 0) {
				inputChannelsWithData.wait();
			}
			currentChannel = inputChannelsWithData.remove();
			moreAvailable = inputChannelsWithData.size() > 0;
		}
		final BufferAndAvailability result = currentChannel.getNextBuffer();
		final Buffer buffer = result.buffer();
		return new BufferOrEvent(buffer, currentChannel.getChannelIndex(), moreAvailable);
	}
```

在该函数内主要有两个重要的方法，requestPartitions和getNextBuffer()，这两个方法都是InputChannel类中的抽象方法，在LocalInputChannel和RemoteInputChannel中具体实现。         RequestPartitions方法的作用是触发所有的输入通道向ResultSubpartition发起请求，如果是Local，会比较简单，直接获取到对应的ResultSubPartition，不需要跨节点网络通信；如果是remote，这时候会需要跨界点远程网络通信，会创建一个PartitionRequestClient来衔接通信层跟输入通道。具体怎么用Netty跨节点传输后续分析。

 getNextBuffer方法的作用是获取ResultSubPartition中的buffer来消费，同样的会分为Local和remote两种模式。如果是remote模式的话，会将buffer存储到堵塞队列inputChannelsWithData中，当有可获取数据的inputChannel之后，即可获得buffer。

### 反序列化阶段

为了能够顺利的读取反序列化器的buffer数据，Flink提供了反序列化器RecordDeserializer，该接口有两种实现：AdaptiveSpanningRecordDeserializer(适用于数据大小适中且跨段的记录的反序列化)和SpillingAdaptiveSpanningRecordDeserializer(支持将溢出的数据写入临时文件)。和RecordWriter一样，每个写入器都关联着结果分区ResultPartition，相应的，每个读取器也关联着对等的输入网关InputGate，首先在RecordReader创建的时候，会根据inputChannel的数量，保证每个InputChannel有一个反序列化器，默认是带有溢出功能的反序列化器，部分代码如下：

```java
this.recordDeserializers = new SpillingAdaptiveSpanningRecordDeserializer[inputGate.getNumberOfInputChannels()];
for (int i = 0; i < recordDeserializers.length; i++) {
	recordDeserializers[i] = new SpillingAdaptiveSpanningRecordDeserializer<T>(tmpDirectories);
}
```

然后将Buffer中的数据反序列化为记录是由getNextRecord方法和setNextBuffer方法协作完成。getNextRecord方法会传入目标记录的引用并在内部将数据填入目标记录。