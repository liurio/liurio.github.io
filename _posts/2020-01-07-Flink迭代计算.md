---
logout: post
title: Flink迭代计算
tags: [flink,all]
---

Flink对流处理和批处理都提供了迭代计算，也是较spark优秀的地方。

## DataSet

所谓迭代运算，就是给定一个初值，用所给的算法公式计算初值得到一个中间结果，然后将中间结果作为输入参数进行反复计算，在满足一定条件的时候得到计算结果。

### Bulk Iterate(全量迭代)

这种迭代方式称为全量迭代，它会将整个数据输入，经过一定的迭代次数，最终得到你想要的结果，如下图所示：

![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20190518135510776.png)

从上图可以看出，该迭代过程主要分为以下几步：

1. Iteration Input（迭代输入）：是初始输入值或者上一次迭代计算的结果
2. Step Function（step函数）：它迭代计算DataSet，由一系列的operator组成，比如map，flatMap，join等，取决于具体的业务逻辑。
3. Next Partial Solution（中间结果）：每一次迭代计算的结果，被发送到下一次迭代计算中。
4. Iteration Result（迭代结果）：最后一次迭代输出的结果，被输出到datasink或者发送到下游处理。

**迭代结束的条件**

> - 达到最大迭代次数
> - 自定义收敛聚合函数

例子：给定一组数据，输出迭代10次每次加1后的结果，如下图所示，

![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20190518140154507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2,size_16,color_FFFFFF,t_70)

### Delta Iterate(增量迭代)

这种迭代方式称为增量迭代，它并不是每次去迭代全量的数据，而是有两个数据集，WorkSet和SolutionSet，每次输入这两个数据集进行迭代运算（这两个数据集可以相等），然后对workset进行迭代运算并且不断的更新solutionset，直到达到迭代次数或者workset为空，输出迭代计算结果。如下图所示：
![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20190518141306901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3MTQyMzQ2,size_16,color_FFFFFF,t_70)

主要需要下面的几步：

1. Iteration Input：读取初始WorkSet和初始Solution Set作为第一次迭代计算的输入
2. Step Function：step函数，每次迭代计算dataset，由map，flatmap以及join等操作组成的，具体有业务逻辑决定。
3. Next Workset/Update Solution Set：Next WorkSet驱动迭代计算，将计算结果反馈到下一次迭代计算中，Solution Set将被不断的更新。两个数据集都在step函数中被迭代计算。
4. Iteration Result：在最后一次迭代计算完成后，Solution Set将被输出或者输入下游处理。

**迭代终止条件**

> - 达到迭代次数或者work Set为空（默认）
> - 自定义聚合器收敛

## DataStream

流式迭代计算方法和批处理类似，不过流处理中无法设置迭代的最大次数。取而代之的是，你能够指定等待反馈输入的最大时间间隔（假设超过该时间间隔没有反馈元素到来。那么该迭代将会终止），通过应用split或filter转换，你能够指定流的哪一部分用于反馈给迭代头，哪一部分分发给下游。

**迭代终止条件**

> - 超过设置的最大时间间隔
> - 自定义聚合收敛

例：Fibonacci数列的计算

![img](https://gitee.com/liurio/image_save/raw/master/flink/delta_iterate.jpg)

```java
public class FibonacciDelta {
    public static String ITERATE_FLAG="iterate";
    public static String OUTPUT_FLAG="output";
    public static int MAX_RANDOM_VALUE=20;
    public static int OVERFLOW_THRESHOLD=100;

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment
                .getExecutionEnvironment().setBufferTimeout(1);

        // 增加数据源，一个二元组1~10之间的两个随机数(20组)
        DataStream<Tuple2<Integer, Integer>> inputStream = env.addSource(new RandomFibonacciSource());

        //五元组，前两个指初始的数据源，第三四位置是每次迭代的临时存储值。第五个是迭代的代数
        IterativeStream<Tuple5<Integer, Integer, Integer, Integer, Integer>> iterativeStream =
                inputStream.map(new TupleTransformMapFunction()).iterate(5000);

        //执行斐波那契数列的步函数并产生斐波那契数列流
        DataStream<Tuple5<Integer, Integer, Integer, Integer, Integer>> fibonacciStream =
                iterativeStream.map(new FibonacciCalcStepFunction());

        //对最新的两个值进行判断，看它们是否超过了指定的阈值。超过了阈值的元组将会被输出，而没有超过的则会再次参与迭代
        //产生两个不同的分支，为此构建了分支流
        SplitStream<Tuple5<Integer, Integer, Integer, Integer, Integer>> branchedStream =
                fibonacciStream.split(new FibonacciOverflowSelector());

        //迭代流的closeWith方法反馈给迭代头
        iterativeStream.closeWith(branchedStream.select(ITERATE_FLAG));

        //对于需要输出的，简单的重构下输出
        DataStream<Tuple3<Integer, Integer, Integer>> outputStream = branchedStream
                .select(OUTPUT_FLAG).map(new BuildOutputTupleMapFunction());

        outputStream.print();
        env.execute("Streaming Iteration Example");
    }
}

class RandomFibonacciSource implements SourceFunction<Tuple2<Integer, Integer>> {

    private Random random = new Random();
    private volatile boolean isRunning = true;
    private int counter = 0;

    public void run(SourceFunction.SourceContext<Tuple2<Integer, Integer>> ctx) throws Exception {
        while (isRunning && counter < MAX_RANDOM_VALUE) {
            int first = random.nextInt(MAX_RANDOM_VALUE / 2 - 1) + 1;
            int second = random.nextInt(MAX_RANDOM_VALUE / 2 -1) + 1;

            if (first > second) continue;

            ctx.collect(new Tuple2<Integer, Integer>(first, second));
            counter++;
            Thread.sleep(50);
        }
    }

    public void cancel() {
        isRunning = false;
    }
}

class TupleTransformMapFunction extends RichMapFunction<Tuple2<Integer, Integer>,
        Tuple5<Integer, Integer, Integer, Integer, Integer>> {
    public Tuple5<Integer, Integer, Integer, Integer, Integer> map(
            Tuple2<Integer, Integer> inputTuples) throws Exception {
        return new Tuple5<Integer, Integer, Integer, Integer, Integer>(
                inputTuples.f0,
                inputTuples.f1,
                inputTuples.f0,
                inputTuples.f1,
                0);
    }
}
```

